{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, delimiter=','):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                data.append(line.strip().split(delimiter))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing line: {line}. Error: {e}\")\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(text_a, text_b):\n",
    "    return f\"{text_a} [MASK] {text_b}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def get_ollama_predictions(data):\n",
    "    predictions = []\n",
    "    for i, prompt in enumerate(data['prompt']):\n",
    "        try:\n",
    "            response = ollama.chat(model='llama3', messages=[\n",
    "                {'role': 'user', 'content': prompt},\n",
    "            ])\n",
    "            predictions.append(response['message']['content'])\n",
    "        except Exception as e:\n",
    "            predictions.append(str(e))\n",
    "        \n",
    "        # Print progress every 100 steps\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Processed {i} prompts\")\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = load_data('dev-0/in_1.csv', delimiter=',')\n",
    "dev_labels = load_data('dev-0/expected.tsv', delimiter='\\t')\n",
    "test_data = load_data('test-A/in_1.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['combined'] = dev_data.iloc[:, 0] + ' [MASK] ' + dev_data.iloc[:, 1]\n",
    "test_data['combined'] = test_data.iloc[:, 0] + ' [MASK] ' + test_data.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['prompt'] = dev_data.apply(lambda row: create_prompt(row.iloc[0], row.iloc[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['prompt'] = test_data.apply(lambda row: create_prompt(row.iloc[0], row.iloc[1]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 prompts\n",
      "Processed 100 prompts\n",
      "Processed 200 prompts\n",
      "Processed 300 prompts\n",
      "Processed 400 prompts\n",
      "Processed 500 prompts\n",
      "Processed 600 prompts\n",
      "Processed 700 prompts\n",
      "Processed 800 prompts\n",
      "Processed 900 prompts\n",
      "Processed 1000 prompts\n",
      "Processed 1100 prompts\n",
      "Processed 1200 prompts\n",
      "Processed 1300 prompts\n",
      "Processed 1400 prompts\n",
      "Processed 1500 prompts\n",
      "Processed 1600 prompts\n",
      "Processed 1700 prompts\n",
      "Processed 1800 prompts\n",
      "Processed 1900 prompts\n",
      "Processed 2000 prompts\n",
      "Processed 2100 prompts\n",
      "Processed 2200 prompts\n",
      "Processed 2300 prompts\n",
      "Processed 2400 prompts\n",
      "Processed 2500 prompts\n",
      "Processed 2600 prompts\n",
      "Processed 2700 prompts\n",
      "Processed 2800 prompts\n",
      "Processed 2900 prompts\n",
      "Processed 3000 prompts\n",
      "Processed 3100 prompts\n",
      "Processed 3200 prompts\n",
      "Processed 3300 prompts\n",
      "Processed 3400 prompts\n",
      "Processed 3500 prompts\n",
      "Processed 3600 prompts\n",
      "Processed 3700 prompts\n",
      "Processed 3800 prompts\n",
      "Processed 3900 prompts\n",
      "Processed 4000 prompts\n",
      "Processed 4100 prompts\n",
      "Processed 4200 prompts\n",
      "Processed 4300 prompts\n",
      "Processed 4400 prompts\n",
      "Processed 4500 prompts\n",
      "Processed 4600 prompts\n",
      "Processed 4700 prompts\n",
      "Processed 4800 prompts\n",
      "Processed 4900 prompts\n",
      "Processed 5000 prompts\n",
      "Processed 5100 prompts\n",
      "Processed 5200 prompts\n",
      "Processed 5300 prompts\n",
      "Processed 5400 prompts\n",
      "Processed 5500 prompts\n",
      "Processed 5600 prompts\n",
      "Processed 5700 prompts\n",
      "Processed 5800 prompts\n",
      "Processed 5900 prompts\n",
      "Processed 6000 prompts\n",
      "Processed 6100 prompts\n",
      "Processed 6200 prompts\n",
      "Processed 6300 prompts\n",
      "Processed 6400 prompts\n",
      "Processed 6500 prompts\n",
      "Processed 6600 prompts\n",
      "Processed 6700 prompts\n",
      "Processed 6800 prompts\n",
      "Processed 6900 prompts\n",
      "Processed 7000 prompts\n",
      "Processed 7100 prompts\n",
      "Processed 7200 prompts\n",
      "Processed 7300 prompts\n",
      "Processed 7400 prompts\n",
      "Processed 7500 prompts\n",
      "Processed 7600 prompts\n",
      "Processed 7700 prompts\n",
      "Processed 7800 prompts\n",
      "Processed 7900 prompts\n",
      "Processed 8000 prompts\n",
      "Processed 8100 prompts\n",
      "Processed 8200 prompts\n",
      "Processed 8300 prompts\n",
      "Processed 8400 prompts\n",
      "Processed 8500 prompts\n",
      "Processed 8600 prompts\n",
      "Processed 8700 prompts\n",
      "Processed 8800 prompts\n",
      "Processed 8900 prompts\n",
      "Processed 9000 prompts\n",
      "Processed 9100 prompts\n",
      "Processed 9200 prompts\n",
      "Processed 9300 prompts\n",
      "Processed 9400 prompts\n",
      "Processed 9500 prompts\n",
      "Processed 9600 prompts\n",
      "Processed 9700 prompts\n",
      "Processed 9800 prompts\n",
      "Processed 9900 prompts\n",
      "Processed 10000 prompts\n",
      "Processed 10100 prompts\n",
      "Processed 10200 prompts\n",
      "Processed 10300 prompts\n",
      "Processed 10400 prompts\n",
      "Processed 10500 prompts\n"
     ]
    }
   ],
   "source": [
    "dev_data['prediction'] = get_ollama_predictions(dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 prompts\n",
      "Processed 100 prompts\n",
      "Processed 200 prompts\n",
      "Processed 300 prompts\n",
      "Processed 400 prompts\n",
      "Processed 500 prompts\n",
      "Processed 600 prompts\n",
      "Processed 700 prompts\n",
      "Processed 800 prompts\n",
      "Processed 900 prompts\n",
      "Processed 1000 prompts\n",
      "Processed 1100 prompts\n",
      "Processed 1200 prompts\n",
      "Processed 1300 prompts\n",
      "Processed 1400 prompts\n",
      "Processed 1500 prompts\n",
      "Processed 1600 prompts\n",
      "Processed 1700 prompts\n",
      "Processed 1800 prompts\n",
      "Processed 1900 prompts\n",
      "Processed 2000 prompts\n",
      "Processed 2100 prompts\n",
      "Processed 2200 prompts\n",
      "Processed 2300 prompts\n",
      "Processed 2400 prompts\n",
      "Processed 2500 prompts\n",
      "Processed 2600 prompts\n",
      "Processed 2700 prompts\n",
      "Processed 2800 prompts\n",
      "Processed 2900 prompts\n",
      "Processed 3000 prompts\n",
      "Processed 3100 prompts\n",
      "Processed 3200 prompts\n",
      "Processed 3300 prompts\n",
      "Processed 3400 prompts\n",
      "Processed 3500 prompts\n",
      "Processed 3600 prompts\n",
      "Processed 3700 prompts\n",
      "Processed 3800 prompts\n",
      "Processed 3900 prompts\n",
      "Processed 4000 prompts\n",
      "Processed 4100 prompts\n",
      "Processed 4200 prompts\n",
      "Processed 4300 prompts\n",
      "Processed 4400 prompts\n",
      "Processed 4500 prompts\n",
      "Processed 4600 prompts\n",
      "Processed 4700 prompts\n",
      "Processed 4800 prompts\n",
      "Processed 4900 prompts\n",
      "Processed 5000 prompts\n",
      "Processed 5100 prompts\n",
      "Processed 5200 prompts\n",
      "Processed 5300 prompts\n",
      "Processed 5400 prompts\n",
      "Processed 5500 prompts\n",
      "Processed 5600 prompts\n",
      "Processed 5700 prompts\n",
      "Processed 5800 prompts\n",
      "Processed 5900 prompts\n",
      "Processed 6000 prompts\n",
      "Processed 6100 prompts\n",
      "Processed 6200 prompts\n",
      "Processed 6300 prompts\n",
      "Processed 6400 prompts\n",
      "Processed 6500 prompts\n",
      "Processed 6600 prompts\n",
      "Processed 6700 prompts\n",
      "Processed 6800 prompts\n",
      "Processed 6900 prompts\n",
      "Processed 7000 prompts\n",
      "Processed 7100 prompts\n",
      "Processed 7200 prompts\n",
      "Processed 7300 prompts\n",
      "Processed 7400 prompts\n"
     ]
    }
   ],
   "source": [
    "test_data['prediction'] = get_ollama_predictions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data[['prediction']].to_csv('dev-0/out.tsv', sep='\\t', index=False, header=False)\n",
    "test_data[['prediction']].to_csv('test-A/out.tsv', sep='\\t', index=False, header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
